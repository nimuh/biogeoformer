sequence = dplyr::first(sequence),
cycles_list = list(unique(c(
cycle  [!is.na(cycle)  & cycle  != "nocycle"],
cycle2 [!is.na(cycle2) & cycle2 != "nocycle"],
cycle3 [!is.na(cycle3) & cycle3 != "nocycle"]
))),
.groups = "drop"
) %>%
mutate(
cycle  = map_chr(cycles_list, ~ if (length(.x) >= 1) .x[[1]] else "nocycle"),
cycle2 = map_chr(cycles_list, ~ if (length(.x) >= 2) .x[[2]] else "nocycle"),
cycle3 = map_chr(cycles_list, ~ if (length(.x) >= 3) .x[[3]] else "nocycle")
) %>%
select(id, gene, database, cycle, cycle2, cycle3, sequence)
}
fixed_multicycle <- reconcile_multicycle(dup_multicycle)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(Biostrings)
library(stringr)
library(phylotools)
library(dplyr)
library(reticulate)
library(flextable)
library(officer)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(Biostrings)
library(stringr)
library(phylotools)
library(dplyr)
library(reticulate)
library(flextable)
library(officer)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
grouped_metadata_mcycdb <- read.csv("metadata_pathways/grouped_metadata_multigroups_mcycdb.csv")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
grouped_metadata_mcycdb <- read.csv("../../cycdb_csv/metadata_with_pathways/grouped_metadata_multigroups_mcycdb.csv")
grouped_metadata_scycdb <- read.csv("../../cycdb_csv/metadata_with_pathways/grouped_metadata_multigroups_scycdb.csv")
grouped_metadata_ncycdb <- read.csv("../../cycdb_csv/metadata_with_pathways/grouped_metadata_multigroups_ncyc.csv")
grouped_metadata_pcycdb <- read.csv("../../cycdb_csv/metadata_with_pathways/grouped_metadata_multigroups_pcycdb.csv")
combined_grouped_metadata <- rbind(grouped_metadata_mcycdb, grouped_metadata_ncycdb, grouped_metadata_scycdb, grouped_metadata_pcycdb)
combined_grouped_metadata <- select(combined_grouped_metadata, -X)
gene2pathway <- combined_grouped_metadata %>% select(gene, cycle, cycle2, cycle3)
gene2pathway <- unique(gene2pathway)
write.csv(combined_grouped_metadata, "../../cycdb_csv/metadata_with_pathways/combined_grouped_metadata.csv", row.names = FALSE)
write.csv(gene2pathway, "../../cycdb_csv/metadata_with_pathways/gene2pathwaymap.csv", row.names = FALSE)
combined_grouped_metadata <- read.csv("../../cycdb_csv/metadata_with_pathways/combined_grouped_metadata.csv")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
metadata_combined <- read.csv("../../cycdb_csv/metadata_with_pathways/combined_grouped_metadata.csv")
sequences <- read.fasta("../../combined_cycdb/combined100.faa")
colnames(sequences) <- c("id", "sequence")
merged_met_seq <- merge(x = metadata_combined, y = sequences, by = "id")
View(grouped_metadata_ncycdb)
dups_merged_met_seq <- merged_met_seq %>%
group_by(id) %>%
filter(n() > 1) %>%
arrange(id)
clean_query_data_ml <- merged_met_seq %>%
group_by(id) %>%
filter(n() == 1) %>%
ungroup()
dup_summary <- dups_merged_met_seq %>%
group_by(id) %>%
summarise(
n_genes  = n_distinct(gene),
n_cycles = n_distinct(c(cycle, cycle2, cycle3)[c(cycle, cycle2, cycle3) != "nocycle"]),
.groups = "drop"
)
# A: multiple genes -> drop
ids_multigene <- dup_summary %>%
filter(n_genes > 1) %>%
select(id)
# B: one gene, multiple cycles -> fix later
ids_multicycle <- dup_summary %>%
filter(n_genes == 1, n_cycles > 1) %>%
select(id)
ids_bad <- bind_rows(ids_multigene, ids_multicycle)
clean_data <- anti_join(merged_met_seq, ids_bad, by = "id")
dup_multicycle <- inner_join(merged_met_seq, ids_multicycle, by = "id")
library(dplyr)
library(purrr)
reconcile_multicycle <- function(multicycle_df) {
multicycle_df %>%
group_by(id) %>%
summarise(
gene     = dplyr::first(gene),
database = dplyr::first(database),
sequence = dplyr::first(sequence),
cycles_list = list(unique(c(
cycle  [!is.na(cycle)  & cycle  != "nocycle"],
cycle2 [!is.na(cycle2) & cycle2 != "nocycle"],
cycle3 [!is.na(cycle3) & cycle3 != "nocycle"]
))),
.groups = "drop"
) %>%
mutate(
cycle  = map_chr(cycles_list, ~ if (length(.x) >= 1) .x[[1]] else "nocycle"),
cycle2 = map_chr(cycles_list, ~ if (length(.x) >= 2) .x[[2]] else "nocycle"),
cycle3 = map_chr(cycles_list, ~ if (length(.x) >= 3) .x[[3]] else "nocycle")
) %>%
select(id, gene, database, cycle, cycle2, cycle3, sequence)
}
fixed_multicycle <- reconcile_multicycle(dup_multicycle)
dups_fixed_multicycle <- fixed_multicycle %>%
group_by(id) %>%
filter(n() > 1) %>%
arrange(id)
combined_data <- bind_rows(clean_data, fixed_multicycle) %>%
distinct()
dups_fixed_combined_data <- combined_data %>%
group_by(id) %>%
filter(n() > 1) %>%
arrange(id)
combined_data <- combined_data %>%
distinct(id, .keep_all = TRUE)
dups_fixed_combined_data <- combined_data %>%
group_by(id) %>%
filter(n() > 1) %>%
arrange(id)
combined_data_test_ws <- combined_data %>%
mutate(id = trimws(id))
dups_fixed_whitespace_check <- combined_data_test_ws %>%
group_by(id) %>%
filter(n() > 1) %>%
arrange(id)
#df$combined <- ifelse(df$column2 == "nocycle", df$column1, paste(df$column1, df$column2, sep = ","))
combined_data$combined_cycle <- ifelse(combined_data$cycle2 == "nocycle", combined_data$cycle, paste(combined_data$cycle, combined_data$cycle2, sep = ","))
unique(combined_data$cycle3)
df_count <- combined_data %>%
group_by(cycle) %>%
summarise(Count = n()) %>%
arrange(desc(Count))
# Convert Class into a factor with levels ordered by Count
df_count$cycle <- factor(df_count$cycle, levels = df_count$cycle)
# Create the plot
ggplot(df_count, aes(x = cycle, y = Count)) +
geom_bar(stat = "identity") +
coord_flip() + # This makes the plot horizontal
theme_minimal() +
labs(x = "Class", y = "Count", title = "Count of Classes in Descending Order")
df_count <- combined_data %>%
group_by(combined_cycle) %>%
summarise(Count = n()) %>%
arrange(desc(Count))
# Convert Class into a factor with levels ordered by Count
df_count$cycle <- factor(df_count$combined_cycle, levels = df_count$combined_cycle)
# Create the plot
ggplot(df_count, aes(x = cycle, y = Count)) +
geom_bar(stat = "identity") +
coord_flip() + # This makes the plot horizontal
theme_minimal() +
labs(x = "Class", y = "Count", title = "Count of Classes in Descending Order")
merged_met_seq_sc <- filter(combined_data, cycle != "nocycle", cycle2 == "nocycle", combined_cycle != "aom")
merged_met_seq_cenaom <- filter(combined_data, combined_cycle == "cenmetpat,aom")
merged_met_seq_sc <- rbind(merged_met_seq_sc, merged_met_seq_cenaom)
library(dplyr)
# Identify genes that fall into more than one cycle
genes_multiple_cycles <- merged_met_seq_sc %>%
select(gene, combined_cycle) %>%
distinct() %>%
group_by(gene) %>%
summarise(n_cycles = n_distinct(combined_cycle), .groups = "drop") %>%
filter(n_cycles > 1) %>%
pull(gene)  # this makes it a character vector of gene names
# Step 2: Remove rows with those genes
merged_met_seq_sc <- merged_met_seq_sc %>%
filter(!gene %in% genes_multiple_cycles)
genes_multiple_cycles <- merged_met_seq_sc %>%
select(gene, combined_cycle) %>%
distinct() %>%
group_by(gene) %>%
summarise(n_cycles = n_distinct(combined_cycle), .groups = "drop") %>%
filter(n_cycles > 1) %>%
pull(gene)
df_count <- merged_met_seq_sc %>%
group_by(combined_cycle) %>%
summarise(Count = n()) %>%
arrange(desc(Count))
# Convert Class into a factor with levels ordered by Count
df_count$cycle <- factor(df_count$combined_cycle, levels = df_count$combined_cycle)
# Create the plot
ggplot(df_count, aes(x = cycle, y = Count)) +
geom_bar(stat = "identity") +
coord_flip() + # This makes the plot horizontal
theme_minimal() +
labs(x = "Class", y = "Count", title = "Count of Classes in Descending Order")
# Create the gene count table
gene_cycle_counts <- merged_met_seq_sc %>%
group_by(combined_cycle, gene) %>%
summarise(gene_count = n(), .groups = "drop") %>%
arrange(combined_cycle, desc(gene_count))
# Make a flextable
ft <- flextable(gene_cycle_counts)
ft <- autofit(ft)
# Export to Word document
doc <- read_docx() %>%
body_add_par("Supplementary Table: Gene counts per combined cycle class", style = "heading 1") %>%
body_add_flextable(ft)
# Save the Word document
print(doc, target = "~/Dropbox/cycformer_manuscript/figs/gene_cycle_counts_table_aug25.docx")
write.csv(gene_cycle_counts, "~/Dropbox/cycformer_manuscript/figs/gene_cycle_counts_table_aug25.csv")
# Save the Word document
print(doc, target = "../../BioGeoFormer_db/BioGeoFormer_db_overview.docx")
# Create the gene count table
gene_cycle_counts <- merged_met_seq_sc %>%
group_by(combined_cycle, gene) %>%
summarise(gene_count = n(), .groups = "drop") %>%
arrange(combined_cycle, desc(gene_count))
# Make a flextable
ft <- flextable(gene_cycle_counts)
ft <- autofit(ft)
# Export to Word document
doc <- read_docx() %>%
body_add_par("Supplementary Table: Gene counts per combined cycle class", style = "heading 1") %>%
body_add_flextable(ft)
# Save the Word document
print(doc, target = "../../BioGeoFormer_db/BioGeoFormer_db_overview.docx")
write.csv(gene_cycle_counts, "../../BioGeoFormer_db/BioGeoFormer_db_overview.csv")
dups_merged_gene_counts<- gene_cycle_counts %>%
group_by(gene) %>%
filter(n() > 1) %>%
arrange(gene)
dups_merged_met_seq_sc<- merged_met_seq_sc %>%
group_by(id) %>%
filter(n() > 1) %>%
arrange(id)
dups_merged_gene_counts
dups_merged_met_seq_sc
merged_met_seq_sc <- select(merged_met_seq_sc, id, gene, combined_cycle, sequence)
colnames(merged_met_seq_sc) <- c('id', 'gene', 'cycle', 'sequence')
write.csv(merged_met_seq_sc, "../../BioGeoFormer_db/BioGeoFormer_db.csv", row.names = F)
write.csv(gene_cycle_counts, "../../BioGeoFormer_db/BioGeoFormer_db_overview.csv", row.names = FALSE)
unique(merged_met_seq_sc$cycle)
read.csv("~/Dropbox/cycformer_data_aug26/data_ml/combined100_ml_aug26.csv")
test <- read.csv("~/Dropbox/cycformer_data_aug26/data_ml/combined100_ml_aug26.csv")
library(tidyverse)
library(ggplot2)
library(Biostrings)
library(stringr)
library(phylotools)
library(dplyr)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
df <- read.csv("../../BioGeoFormer_db/BioGeoFormer_db.csv")
check_gene_cycle_overlap <- function(df) {
# Collapse to distinct gene–cycle pairs in case there are duplicate rows
gene_cycle_unique <- df %>%
distinct(gene, cycle)
# Count how many distinct cycles each gene appears in
gene_cycle_counts <- gene_cycle_unique %>%
group_by(gene) %>%
summarise(n_cycles = n_distinct(cycle),
cycles = paste(sort(unique(cycle)), collapse = ", ")) %>%
filter(n_cycles > 1)
if (nrow(gene_cycle_counts) == 0) {
cat("no genes appear in more than one cycle.\n")
return(invisible(NULL))
} else {
cat("Found genes that occur in multiple cycles:\n")
print(gene_cycle_counts)
return(gene_cycle_counts)
}
}
check_gene_cycle_overlap(df)
dups_df<- df %>%
group_by(id) %>%
filter(n() > 1) %>%
arrange(id)
print(dups_df)
split_data <- split(df, df$cycle)
split_data_selected <- lapply(split_data, function(x) x[, c("id", "sequence")])
split_data_selected <- lapply(split_data_selected, function(x) {
colnames(x) <- c("seq.name", "seq.text")
return(x)
})
row_counts <- sapply(split_data_selected, nrow)
median(row_counts)
getwd()
setwd("../../BGF_clustering/cycle_division_split")
for (category_name in names(split_data_selected)) {
dat2fasta(split_data_selected[[category_name]], paste0("combined100_", category_name, ".faa"))
}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
setwd('../../BGF_clustering/train_test_val_final/')
library(tidyverse)
selected_dir <- "."
# function to check one similarity level
check_splits <- function(train, val, test, level) {
cat("\n=== Level", level, "===\n")
summary <- tibble(
level = level,
train_unique = n_distinct(train$id),
val_unique   = n_distinct(val$id),
test_unique  = n_distinct(test$id),
within_dup_train = train %>% count(id) %>% filter(n > 1) %>% nrow(),
within_dup_val   = val   %>% count(id) %>% filter(n > 1) %>% nrow(),
within_dup_test  = test  %>% count(id) %>% filter(n > 1) %>% nrow(),
leak_count = 0
)
# within-split duplicates (console print)
for (nm in c("train","val","test")) {
d <- switch(nm, train = train, val = val, test = test)
dups <- d %>% count(id) %>% filter(n > 1)
if (nrow(dups) == 0) {
cat("[WITHIN]", nm, ": no duplicate ids ✅\n")
} else {
cat("[WITHIN]", nm, ":", nrow(dups), "duplicate ids (e.g.",
paste(head(dups$id, 5), collapse = ", "), ")\n")
}
}
# cross-split overlaps
ids_t <- unique(train$id)
ids_v <- unique(val$id)
ids_s <- unique(test$id)
leaks <- unique(c(intersect(ids_t, ids_v),
intersect(ids_t, ids_s),
intersect(ids_v, ids_s)))
if (length(leaks) == 0) {
cat("[LEAKAGE] no cross-split overlaps ✅\n")
} else {
cat("[LEAKAGE]", length(leaks), "ids overlap across splits (e.g.",
paste(head(leaks, 5), collapse = ", "), ")\n")
summary$leak_count <- length(leaks)
}
# counts
cat(sprintf("[COUNTS] train=%d, val=%d, test=%d\n",
n_distinct(train$id), n_distinct(val$id), n_distinct(test$id)))
return(summary)
}
# detect levels present
files <- list.files(selected_dir, pattern = "final_selected_.*\\.csv$")
levels <- str_match(files, "_(\\d{2,3})\\.csv$")[,2] %>% unique() %>% sort()
# run checks for each level and collect summaries
report <- list()
for (lv in levels) {
train <- read_csv(file.path(selected_dir, paste0("final_selected_train_", lv, ".csv")),
show_col_types = FALSE)
val   <- read_csv(file.path(selected_dir, paste0("final_selected_val_", lv, ".csv")),
show_col_types = FALSE)
test  <- read_csv(file.path(selected_dir, paste0("final_selected_test_", lv, ".csv")),
show_col_types = FALSE)
report[[lv]] <- check_splits(train, val, test, level = lv)
}
summary_tbl <- bind_rows(report)
cat("\n=== SUMMARY TABLE ===\n")
print(summary_tbl)
write_csv(summary_tbl, file.path(selected_dir, "../cluster_summary/final_train_test_val_summary.csv"))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# Set your main directory
main_dir <- "../../BGF_clustering/train_test_val_final/"
# Get full file paths for everything in the folder
files <- list.files(main_dir, full.names = TRUE)
# Loop through each file
for (f in files) {
# Extract just the filename
fname <- basename(f)
# Determine destination based on filename pattern
if (grepl("test", fname, ignore.case = TRUE)) {
dest_dir <- file.path(main_dir, "test")
} else if (grepl("val", fname, ignore.case = TRUE) || grepl("validation", fname, ignore.case = TRUE)) {
dest_dir <- file.path(main_dir, "validation")
} else if (grepl("train", fname, ignore.case = TRUE)) {
dest_dir <- file.path(main_dir, "train")
} else {
next  # skip anything that doesn't match
}
# Create destination directory if it doesn't exist
if (!dir.exists(dest_dir)) dir.create(dest_dir, recursive = TRUE)
# Build destination file path
dest_file <- file.path(dest_dir, fname)
# Move the file
file.rename(f, dest_file)
# Optional: print progress
message("Moved ", fname, " -> ", dest_dir)
}
message("✅ All files sorted into train/test/validation folders.")
library(tidyverse)
library(Biostrings)
# Function to process a CSV file and write it as a FASTA file
process_csv_to_fasta <- function(file_path, output_folder) {
# Read the CSV file
df <- read.csv(file_path, stringsAsFactors = FALSE)
# Extract the base filename (without extension) to use in FASTA file naming
base_filename <- tools::file_path_sans_ext(basename(file_path))
# Function to write the dataframe as a FASTA file
write_fasta_protein <- function(df, filename) {
# Create an AAStringSet object from the 'sequence' column (protein sequences)
protein_sequences <- AAStringSet(df$sequence)
# Set the names of the sequences using the 'id' column
names(protein_sequences) <- df$id
# Write the protein sequences to a FASTA file
writeXStringSet(protein_sequences, filepath = filename)
}
# Create the output FASTA filename
output_file <- file.path(output_folder, paste0(base_filename, ".fasta"))
# Write the dataframe as a FASTA file
write_fasta_protein(df, output_file)
# Confirmation message
cat("FASTA file has been written to:", output_file, "\n")
}
# Function to process all CSV files in a folder
process_all_csv_in_folder <- function(folder_path, output_folder) {
# Get the list of CSV files in the specified folder
file_list <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)
# Loop through each file and process it
for (file in file_list) {
process_csv_to_fasta(file, output_folder)
}
}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# Example usage
# Specify your input folder and output folder
input_folder <- "../../BGF_clustering/train_test_val_final/validation/"
# Specify your input folder and output folder
input_folder <- "../../BGF_clustering/train_test_val_final/validation/"
output_folder <- "../../BGF_clustering/train_test_val_final/val_fasta/"
# Process all CSV files in the folder
process_all_csv_in_folder(input_folder, output_folder)
# Specify your input folder and output folder
input_folder <- "../../BGF_clustering/train_test_val_final/validation"
output_folder <- "../../BGF_clustering/train_test_val_final/val_fasta"
# Process all CSV files in the folder
process_all_csv_in_folder(input_folder, output_folder)
library(tidyverse)
library(Biostrings)
# Function to process a CSV file and write it as a FASTA file
process_csv_to_fasta <- function(file_path, output_folder) {
# Read the CSV file
df <- read.csv(file_path, stringsAsFactors = FALSE)
# Extract the base filename (without extension) to use in FASTA file naming
base_filename <- tools::file_path_sans_ext(basename(file_path))
# Function to write the dataframe as a FASTA file
write_fasta_protein <- function(df, filename) {
# Create an AAStringSet object from the 'sequence' column (protein sequences)
protein_sequences <- AAStringSet(df$sequence)
# Set the names of the sequences using the 'id' column
names(protein_sequences) <- df$id
# Write the protein sequences to a FASTA file
writeXStringSet(protein_sequences, filepath = filename)
}
# Create the output FASTA filename
output_file <- file.path(output_folder, paste0(base_filename, ".fasta"))
# Write the dataframe as a FASTA file
write_fasta_protein(df, output_file)
# Confirmation message
cat("FASTA file has been written to:", output_file, "\n")
}
# Function to process all CSV files in a folder
process_all_csv_in_folder <- function(folder_path, output_folder) {
# Get the list of CSV files in the specified folder
file_list <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)
# Loop through each file and process it
for (file in file_list) {
process_csv_to_fasta(file, output_folder)
}
}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# Specify your input folder and output folder
input_folder <- "../../BGF_clustering/train_test_val_final/test"
output_folder <- "../../BGF_clustering/train_test_val_final/test_fasta"
# Process all CSV files in the folder
process_all_csv_in_folder(input_folder, output_folder)
library(tidyverse)
library(Biostrings)
# Function to process a CSV file and write it as a FASTA file
process_csv_to_fasta <- function(file_path, output_folder) {
# Read the CSV file
df <- read.csv(file_path, stringsAsFactors = FALSE)
# Extract the base filename (without extension) to use in FASTA file naming
base_filename <- tools::file_path_sans_ext(basename(file_path))
# Function to write the dataframe as a FASTA file
write_fasta_protein <- function(df, filename) {
# Create an AAStringSet object from the 'sequence' column (protein sequences)
protein_sequences <- AAStringSet(df$sequence)
# Set the names of the sequences using the 'id' column
names(protein_sequences) <- df$id
# Write the protein sequences to a FASTA file
writeXStringSet(protein_sequences, filepath = filename)
}
# Create the output FASTA filename
output_file <- file.path(output_folder, paste0(base_filename, ".fasta"))
# Write the dataframe as a FASTA file
write_fasta_protein(df, output_file)
# Confirmation message
cat("FASTA file has been written to:", output_file, "\n")
}
# Function to process all CSV files in a folder
process_all_csv_in_folder <- function(folder_path, output_folder) {
# Get the list of CSV files in the specified folder
file_list <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)
# Loop through each file and process it
for (file in file_list) {
process_csv_to_fasta(file, output_folder)
}
}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# Specify your input folder and output folder
input_folder <- "../../BGF_clustering/train_test_val_final/train"
output_folder <- "../../BGF_clustering/train_test_val_final/train_fasta"
# Process all CSV files in the folder
process_all_csv_in_folder(input_folder, output_folder)
