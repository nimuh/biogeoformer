{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26236,"status":"ok","timestamp":1756875054768,"user":{"displayName":"Jacob Wynne","userId":"04420788155919199366"},"user_tz":420},"id":"gGAU83p5R-7S","outputId":"bd2fdbca-349c-421e-bc9c-4a5625274b61"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17600,"status":"ok","timestamp":1756875073963,"user":{"displayName":"Jacob Wynne","userId":"04420788155919199366"},"user_tz":420},"id":"PYcI4CmISmLa","outputId":"b8e218c6-9c5b-4d9f-fb39-d23d6b56f569"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sympy==1.12\n","  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.12/dist-packages (from sympy==1.12) (1.3.0)\n","Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m217.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sympy\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.3\n","    Uninstalling sympy-1.13.3:\n","      Successfully uninstalled sympy-1.13.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.8.0+cu126 requires sympy\u003e=1.13.3, but you have sympy 1.12 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed sympy-1.12\n"]}],"source":["pip install sympy==1.12"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":307},"id":"elcqeS08ur99"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5c860e7f30948e192e4ea40ed847cd0","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/95.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abf49ac3af8940399b8e2dd25e54676a","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/93.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05b74f6b68ef4a6a84daa22c840a1007","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_0\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set:   0%|          | 0/17270 [00:00\u003c?, ?batch/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n","Processing validation set: 100%|██████████| 17270/17270 [23:33\u003c00:00, 12.22batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.747, ECE: 0.379\n","Optimizing temperature with asymmetric penalty (lambda=0)...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/torch/optim/lbfgs.py:457: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n","Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n","  loss = float(closure())\n"]},{"name":"stdout","output_type":"stream","text":["Optimal temperature: 1.756\n","After temperature - NLL: 3.474, ECE: 0.168\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_0/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_10\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 17270/17270 [23:32\u003c00:00, 12.23batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.747, ECE: 0.379\n","Optimizing temperature with asymmetric penalty (lambda=10)...\n","Optimal temperature: 2.007\n","After temperature - NLL: 3.334, ECE: 0.122\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_10/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_20\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 17270/17270 [23:33\u003c00:00, 12.22batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.747, ECE: 0.379\n","Optimizing temperature with asymmetric penalty (lambda=20)...\n","Optimal temperature: 2.275\n","After temperature - NLL: 3.246, ECE: 0.104\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_20/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_30\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 17270/17270 [23:33\u003c00:00, 12.22batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.747, ECE: 0.379\n","Optimizing temperature with asymmetric penalty (lambda=30)...\n","Optimal temperature: 2.493\n","After temperature - NLL: 3.203, ECE: 0.101\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_30/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_40\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 17270/17270 [23:34\u003c00:00, 12.21batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.747, ECE: 0.379\n","Optimizing temperature with asymmetric penalty (lambda=40)...\n","Optimal temperature: 2.524\n","After temperature - NLL: 3.199, ECE: 0.100\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_40/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_50\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 17270/17270 [23:33\u003c00:00, 12.22batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.747, ECE: 0.379\n","Optimizing temperature with asymmetric penalty (lambda=50)...\n","Optimal temperature: 2.619\n","After temperature - NLL: 3.187, ECE: 0.099\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_50/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_60\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 17270/17270 [23:34\u003c00:00, 12.21batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.747, ECE: 0.379\n","Optimizing temperature with asymmetric penalty (lambda=60)...\n","Optimal temperature: 2.774\n","After temperature - NLL: 3.173, ECE: 0.102\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_60/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_70\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 17270/17270 [23:33\u003c00:00, 12.22batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.747, ECE: 0.379\n","Optimizing temperature with asymmetric penalty (lambda=70)...\n","Optimal temperature: 2.918\n","After temperature - NLL: 3.165, ECE: 0.100\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_70/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_80\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 17270/17270 [23:33\u003c00:00, 12.22batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.747, ECE: 0.379\n","Optimizing temperature with asymmetric penalty (lambda=80)...\n","Optimal temperature: 3.027\n","After temperature - NLL: 3.161, ECE: 0.104\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_80/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_90\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 17270/17270 [23:32\u003c00:00, 12.23batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.747, ECE: 0.379\n","Optimizing temperature with asymmetric penalty (lambda=90)...\n","Optimal temperature: 3.107\n","After temperature - NLL: 3.160, ECE: 0.106\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60/lambda_90/optimal_temperature.pt\n"]}],"source":["import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, EsmForSequenceClassification\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","\n","class TokenizedDataset(Dataset):\n","    def __init__(self, csv_file, tokenizer, label_mapper, max_length=1024):\n","        self.data = pd.read_csv(csv_file)\n","        self.tokenizer = tokenizer\n","        self.label_mapper = label_mapper\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sequence = self.data.iloc[idx]['sequence']\n","        label = self.label_mapper[self.data.iloc[idx]['cycle']]\n","        inputs = self.tokenizer(sequence, return_tensors=\"pt\", padding='max_length',\n","                                truncation=True, max_length=self.max_length)\n","        return {\n","            'input_ids': inputs['input_ids'].squeeze(0),\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","class ModelWithTemperature(nn.Module):\n","    def __init__(self, model):\n","        super(ModelWithTemperature, self).__init__()\n","        self.model = model\n","        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n","\n","    def forward(self, input_ids):\n","        logits = self.model(input_ids).logits\n","        return self.temperature_scale(logits)\n","\n","    def temperature_scale(self, logits):\n","        return logits / self.temperature\n","\n","    def set_temperature(self, valid_loader, save_path, device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\", asym_lambda=50, output_dir=None):\n","        self.to(device)\n","        self.model.eval()\n","        nll_criterion = nn.CrossEntropyLoss().to(device)\n","\n","        logits_list, labels_list = [], []\n","\n","        print(\"Collecting logits and labels...\")\n","        with torch.no_grad():\n","            for batch in tqdm(valid_loader, desc=\"Processing validation set\", unit=\"batch\"):\n","                inputs = batch['input_ids'].to(device)\n","                labels = batch['label'].to(device)\n","                logits = self.model(inputs).logits\n","                logits_list.append(logits)\n","                labels_list.append(labels)\n","\n","        logits = torch.cat(logits_list, dim=0)\n","        labels = torch.cat(labels_list, dim=0)\n","\n","        before_nll = nll_criterion(logits, labels).item()\n","        before_ece = calculate_ece(logits, labels)\n","        print(f\"Before temperature - NLL: {before_nll:.3f}, ECE: {before_ece:.3f}\")\n","\n","        if output_dir:\n","            make_reliability_diagram(logits, labels, title=f\"Before Temperature Scaling\\nECE: {before_ece:.3f}\",\n","                                     save_path=os.path.join(output_dir, \"before_scaling.png\"))\n","        else:\n","            make_reliability_diagram(logits, labels, title=f\"Before Temperature Scaling\\nECE: {before_ece:.3f}\")\n","\n","        optimizer = optim.LBFGS([self.temperature], lr=0.01, max_iter=50)\n","\n","        def closure():\n","            optimizer.zero_grad()\n","            nll_loss = nll_criterion(self.temperature_scale(logits), labels)\n","            asym_loss = asymmetric_confidence_penalty(self.temperature_scale(logits), labels)\n","            loss = nll_loss + asym_lambda * asym_loss\n","            loss.backward()\n","            return loss\n","\n","        print(f\"Optimizing temperature with asymmetric penalty (lambda={asym_lambda})...\")\n","        optimizer.step(closure)\n","\n","        after_logits = self.temperature_scale(logits)\n","        after_nll = nll_criterion(after_logits, labels).item()\n","        after_ece = calculate_ece(after_logits, labels)\n","\n","        print(f\"Optimal temperature: {self.temperature.item():.3f}\")\n","        print(f\"After temperature - NLL: {after_nll:.3f}, ECE: {after_ece:.3f}\")\n","\n","        if output_dir:\n","            make_reliability_diagram(after_logits, labels, title=f\"After Temperature Scaling\\nECE: {after_ece:.3f}\",\n","                                     save_path=os.path.join(output_dir, \"after_scaling.png\"))\n","            with open(os.path.join(output_dir, \"metrics.txt\"), \"w\") as f:\n","                f.write(f\"Lambda: {asym_lambda}\\n\")\n","                f.write(f\"Before Temp - NLL: {before_nll:.3f}, ECE: {before_ece:.3f}\\n\")\n","                f.write(f\"After Temp - NLL: {after_nll:.3f}, ECE: {after_ece:.3f}\\n\")\n","\n","        torch.save(self.temperature.item(), save_path)\n","        print(f\"Saved optimal temperature to: {save_path}\")\n","\n","        return self\n","\n","def asymmetric_confidence_penalty(logits, labels, threshold=0.7, weight=2.0):\n","    softmaxes = F.softmax(logits, dim=1)\n","    confidences, predictions = torch.max(softmaxes, 1)\n","    is_correct = predictions.eq(labels)\n","    overconfident = confidences \u003e threshold\n","    penalty = torch.where(\n","        is_correct,\n","        torch.zeros_like(confidences),\n","        (confidences - threshold) * overconfident.float() * weight\n","    )\n","    return penalty.mean()\n","\n","def calculate_ece(logits, labels, n_bins=15):\n","    softmaxes = F.softmax(logits, dim=1)\n","    confidences, predictions = torch.max(softmaxes, 1)\n","    accuracies = predictions.eq(labels)\n","\n","    bins = torch.linspace(0, 1, n_bins + 1)\n","    bin_lowers = bins[:-1]\n","    bin_uppers = bins[1:]\n","\n","    ece = 0.0\n","    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n","        in_bin = confidences.ge(bin_lower) * confidences.lt(bin_upper)\n","        prop_in_bin = in_bin.float().mean()\n","        if prop_in_bin.item() \u003e 0:\n","            accuracy_in_bin = accuracies[in_bin].float().mean()\n","            avg_confidence_in_bin = confidences[in_bin].mean()\n","            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n","\n","    return ece.item()\n","\n","def make_reliability_diagram(logits, labels, n_bins=15, title=\"Reliability Diagram\", save_path=None):\n","    softmaxes = F.softmax(logits, dim=1)\n","    confidences, predictions = softmaxes.max(1)\n","    accuracies = predictions.eq(labels)\n","\n","    bins = torch.linspace(0, 1, n_bins + 1)\n","    width = 1.0 / n_bins\n","    bin_centers = np.linspace(0, 1.0 - width, n_bins) + width / 2\n","    bin_indices = [confidences.ge(bin_lower) * confidences.lt(bin_upper) for bin_lower, bin_upper in zip(bins[:-1], bins[1:])]\n","\n","    bin_corrects = np.array([torch.mean(accuracies[bin_idx].float()).item() if bin_idx.any() else 0 for bin_idx in bin_indices])\n","    bin_scores = np.array([torch.mean(confidences[bin_idx].float()).item() if bin_idx.any() else 0 for bin_idx in bin_indices])\n","\n","    plt.figure(figsize=(8, 8))\n","    gap = (bin_scores - bin_corrects)\n","    plt.bar(bin_centers, bin_corrects, width=width, alpha=0.5, ec='black', label='Outputs')\n","    plt.bar(bin_centers, gap, bottom=bin_corrects, color='red', alpha=0.5, width=width, hatch='//', edgecolor='r', label='Gap')\n","    plt.plot([0, 1], [0, 1], '--', color='gray')\n","    plt.legend(loc='best', fontsize='small')\n","\n","    ece = calculate_ece(logits, labels, n_bins)\n","    bbox_props = dict(boxstyle=\"round\", fc=\"lightgrey\", ec=\"brown\", lw=2)\n","    plt.text(0.2, 0.85, f\"ECE: {ece:.2f}\", ha=\"center\", va=\"center\", size=20, weight='bold', bbox=bbox_props)\n","\n","    plt.title(title, size=20)\n","    plt.ylabel(\"Accuracy (P[y])\", size=18)\n","    plt.xlabel(\"Confidence\", size=18)\n","    plt.xlim(0, 1)\n","    plt.ylim(0, 1)\n","\n","    if save_path:\n","        plt.savefig(save_path, dpi=600, bbox_inches=\"tight\")\n","    else:\n","        plt.show()\n","    plt.close()\n","\n","if __name__ == \"__main__\":\n","    model_path = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/models/cyc_60\"\n","    validation_csv = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/data/validation_files/final_selected_val_60.csv\"\n","    pickle_path = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/models/cyc_id_maps/cyc_label_id_map_60.pickle\"\n","    tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8m_UR50D\")\n","    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","    with open(pickle_path, 'rb') as f:\n","        label_mapper = pickle.load(f)\n","    label_mapper = {v: k for k, v in label_mapper.items()}\n","\n","    model = EsmForSequenceClassification.from_pretrained(model_path, num_labels=len(label_mapper))\n","    model_with_temp = ModelWithTemperature(model)\n","\n","    val_dataset = TokenizedDataset(validation_csv, tokenizer, label_mapper)\n","    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n","\n","\n","    base_temp_dir = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_60\"\n","    lambda_list = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n","\n","    for asym_lambda in lambda_list:\n","      output_dir = os.path.join(base_temp_dir, f\"lambda_{asym_lambda}\")\n","      os.makedirs(output_dir, exist_ok=True)\n","      temp_save_path = os.path.join(output_dir, \"optimal_temperature.pt\")\n","\n","      print(f\"Saving results to: {output_dir}\")\n","\n","      model_with_temp.set_temperature(\n","          val_loader,\n","          save_path=temp_save_path,\n","          device=device,\n","          asym_lambda=asym_lambda,\n","          output_dir=output_dir\n","      )\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO4Unq1MhirMPQyRdfEcnaA","gpuType":"A100","machine_shape":"hm","name":"","provenance":[{"file_id":"1ZHgaOQ90ID_dtgeK1pYVXQt7EUX6qwPR","timestamp":1756853888893},{"file_id":"1DZDJqKvF5R5sl61_rwDmIGh3ELYUunDv","timestamp":1756853688889},{"file_id":"1a1bGN03_Z2eETVz6yz8Azcr9V0PP2Ann","timestamp":1756853428745},{"file_id":"1J_XfwOrwSHRT5uWuQkoLq76e9NQiznce","timestamp":1756852912238},{"file_id":"1YaVjgEn5hQl8fpJgpUMadby1EqkVdbx4","timestamp":1747763126926},{"file_id":"1BgLPAigcgs4f5Xqd1zM1St7wgEjMjzU7","timestamp":1747685035246},{"file_id":"103_0XRq1YLPKwVLpX49vCYq8m4eTWdVz","timestamp":1743651842921}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"05b74f6b68ef4a6a84daa22c840a1007":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_15a33d2e7d374296805ce55dc5ea78d7","IPY_MODEL_581cbf65109d4f32bf12b9e2b51962e8","IPY_MODEL_675f1907148d4d008f2416a4590a3ee1"],"layout":"IPY_MODEL_a015241c63084b0ebe0f8675310d29f7"}},"0abfefd4725a43938ea8932a97f7ce4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f92730df41345279c085a504606f56f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15a33d2e7d374296805ce55dc5ea78d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8fdc7da291b414b8a6eeed51876c495","placeholder":"​","style":"IPY_MODEL_952f47ab02604eb496e50baf400b319a","value":"special_tokens_map.json: 100%"}},"17a9bbd106154783a1323118f707b243":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"236612079fd7438e9b4856f4bfdd7bc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24414b3ebbfb4f71bfc0ec1d4c6936f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29271a56a2be413892a6fbbe020616c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bc6a6639e8c4bc6bfd311fe405c77fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c66f56add9a42a38c70c79658f1c8c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3040a69ca5574de8989a16d185490ffc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35987371b2a2413bb8cae19cebb4d258":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e42cf4a934414682ba7f4dc760d3bc62","placeholder":"​","style":"IPY_MODEL_2c66f56add9a42a38c70c79658f1c8c8","value":"tokenizer_config.json: 100%"}},"471ae61b068f4fd0a9c1b2a182cbc9ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0fbca28f3164f0e9fdf9e3bdb88aae5","placeholder":"​","style":"IPY_MODEL_0abfefd4725a43938ea8932a97f7ce4d","value":" 93.0/93.0 [00:00\u0026lt;00:00, 11.8kB/s]"}},"581cbf65109d4f32bf12b9e2b51962e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d2399e41997434194b1e2fbb3613fb5","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f92730df41345279c085a504606f56f","value":125}},"675f1907148d4d008f2416a4590a3ee1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97f6418ea9f54f9f9ae32bcb961b7e54","placeholder":"​","style":"IPY_MODEL_2bc6a6639e8c4bc6bfd311fe405c77fe","value":" 125/125 [00:00\u0026lt;00:00, 15.6kB/s]"}},"6e9d8b0938a540b5acb4b5ea32443184":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db22596013224aeba7d3f47876c58c11","max":95,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29271a56a2be413892a6fbbe020616c3","value":95}},"7d2399e41997434194b1e2fbb3613fb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"952f47ab02604eb496e50baf400b319a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97f6418ea9f54f9f9ae32bcb961b7e54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a015241c63084b0ebe0f8675310d29f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a577566d00424dd39a43967d1180a608":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abd3e2fcb6624fa597e7ee8391909933":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abf49ac3af8940399b8e2dd25e54676a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f17afece52da4e51adb7343a9a520136","IPY_MODEL_be769b3d753d45ce992885e1f35fda0a","IPY_MODEL_471ae61b068f4fd0a9c1b2a182cbc9ea"],"layout":"IPY_MODEL_24414b3ebbfb4f71bfc0ec1d4c6936f2"}},"b0fbca28f3164f0e9fdf9e3bdb88aae5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5c860e7f30948e192e4ea40ed847cd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35987371b2a2413bb8cae19cebb4d258","IPY_MODEL_6e9d8b0938a540b5acb4b5ea32443184","IPY_MODEL_cab6a29db0fc4946b0e288c94fb9e330"],"layout":"IPY_MODEL_17a9bbd106154783a1323118f707b243"}},"be769b3d753d45ce992885e1f35fda0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c11208e28aaa4838a7aa619ce88f4525","max":93,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d22ff9aa2f09488ca1db77e4c731ed83","value":93}},"c11208e28aaa4838a7aa619ce88f4525":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8fdc7da291b414b8a6eeed51876c495":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cab6a29db0fc4946b0e288c94fb9e330":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a577566d00424dd39a43967d1180a608","placeholder":"​","style":"IPY_MODEL_abd3e2fcb6624fa597e7ee8391909933","value":" 95.0/95.0 [00:00\u0026lt;00:00, 11.1kB/s]"}},"d22ff9aa2f09488ca1db77e4c731ed83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db22596013224aeba7d3f47876c58c11":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e42cf4a934414682ba7f4dc760d3bc62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f17afece52da4e51adb7343a9a520136":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3040a69ca5574de8989a16d185490ffc","placeholder":"​","style":"IPY_MODEL_236612079fd7438e9b4856f4bfdd7bc3","value":"vocab.txt: 100%"}}}}},"nbformat":4,"nbformat_minor":0}