{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20042,"status":"ok","timestamp":1756895618404,"user":{"displayName":"Jacob Wynne","userId":"04420788155919199366"},"user_tz":420},"id":"gGAU83p5R-7S","outputId":"2d3b5e37-5ef1-4199-9810-c4a8a48af816"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18669,"status":"ok","timestamp":1756895638552,"user":{"displayName":"Jacob Wynne","userId":"04420788155919199366"},"user_tz":420},"id":"PYcI4CmISmLa","outputId":"a982cf0c-c06c-4108-a533-8689fe8ecaf0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sympy==1.12\n","  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.12/dist-packages (from sympy==1.12) (1.3.0)\n","Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/5.7 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/5.7 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sympy\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.3\n","    Uninstalling sympy-1.13.3:\n","      Successfully uninstalled sympy-1.13.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.8.0+cu126 requires sympy\u003e=1.13.3, but you have sympy 1.12 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed sympy-1.12\n"]}],"source":["pip install sympy==1.12"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":307},"id":"elcqeS08ur99"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4aff5fb5649408fbf611a122f7d9b5a","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/95.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f861afbc16894dc6a2dc0eedd69fbf2a","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/93.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"caab387b5c2e4839b085204148fdcdae","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_0\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set:   0%|          | 0/14274 [00:00\u003c?, ?batch/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n","Processing validation set: 100%|██████████| 14274/14274 [19:31\u003c00:00, 12.18batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 5.598, ECE: 0.492\n","Optimizing temperature with asymmetric penalty (lambda=0)...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/torch/optim/lbfgs.py:457: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n","Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n","  loss = float(closure())\n"]},{"name":"stdout","output_type":"stream","text":["Optimal temperature: 1.784\n","After temperature - NLL: 3.786, ECE: 0.268\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_0/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_10\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 14274/14274 [19:30\u003c00:00, 12.19batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 5.598, ECE: 0.492\n","Optimizing temperature with asymmetric penalty (lambda=10)...\n","Optimal temperature: 2.070\n","After temperature - NLL: 3.555, ECE: 0.200\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_10/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_20\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 14274/14274 [19:30\u003c00:00, 12.19batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 5.598, ECE: 0.492\n","Optimizing temperature with asymmetric penalty (lambda=20)...\n","Optimal temperature: 2.277\n","After temperature - NLL: 3.447, ECE: 0.162\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_20/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_30\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 14274/14274 [19:30\u003c00:00, 12.19batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 5.598, ECE: 0.492\n","Optimizing temperature with asymmetric penalty (lambda=30)...\n","Optimal temperature: 2.427\n","After temperature - NLL: 3.389, ECE: 0.134\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_30/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_40\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 14274/14274 [19:30\u003c00:00, 12.20batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 5.598, ECE: 0.492\n","Optimizing temperature with asymmetric penalty (lambda=40)...\n","Optimal temperature: 2.539\n","After temperature - NLL: 3.355, ECE: 0.121\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_40/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_50\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 14274/14274 [19:30\u003c00:00, 12.19batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 5.598, ECE: 0.492\n","Optimizing temperature with asymmetric penalty (lambda=50)...\n","Optimal temperature: 2.626\n","After temperature - NLL: 3.333, ECE: 0.110\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_50/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_60\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 14274/14274 [19:30\u003c00:00, 12.20batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 5.598, ECE: 0.492\n","Optimizing temperature with asymmetric penalty (lambda=60)...\n","Optimal temperature: 2.741\n","After temperature - NLL: 3.309, ECE: 0.094\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_60/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_70\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 14274/14274 [19:30\u003c00:00, 12.19batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 5.598, ECE: 0.492\n","Optimizing temperature with asymmetric penalty (lambda=70)...\n","Optimal temperature: 2.896\n","After temperature - NLL: 3.283, ECE: 0.082\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_70/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_80\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 14274/14274 [19:30\u003c00:00, 12.19batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 5.598, ECE: 0.492\n","Optimizing temperature with asymmetric penalty (lambda=80)...\n","Optimal temperature: 3.135\n","After temperature - NLL: 3.256, ECE: 0.063\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_80/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_90\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 14274/14274 [19:30\u003c00:00, 12.19batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 5.598, ECE: 0.492\n","Optimizing temperature with asymmetric penalty (lambda=90)...\n","Optimal temperature: 3.343\n","After temperature - NLL: 3.242, ECE: 0.052\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30/lambda_90/optimal_temperature.pt\n"]}],"source":["import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, EsmForSequenceClassification\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","\n","class TokenizedDataset(Dataset):\n","    def __init__(self, csv_file, tokenizer, label_mapper, max_length=1024):\n","        self.data = pd.read_csv(csv_file)\n","        self.tokenizer = tokenizer\n","        self.label_mapper = label_mapper\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sequence = self.data.iloc[idx]['sequence']\n","        label = self.label_mapper[self.data.iloc[idx]['cycle']]\n","        inputs = self.tokenizer(sequence, return_tensors=\"pt\", padding='max_length',\n","                                truncation=True, max_length=self.max_length)\n","        return {\n","            'input_ids': inputs['input_ids'].squeeze(0),\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","class ModelWithTemperature(nn.Module):\n","    def __init__(self, model):\n","        super(ModelWithTemperature, self).__init__()\n","        self.model = model\n","        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n","\n","    def forward(self, input_ids):\n","        logits = self.model(input_ids).logits\n","        return self.temperature_scale(logits)\n","\n","    def temperature_scale(self, logits):\n","        return logits / self.temperature\n","\n","    def set_temperature(self, valid_loader, save_path, device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\", asym_lambda=50, output_dir=None):\n","        self.to(device)\n","        self.model.eval()\n","        nll_criterion = nn.CrossEntropyLoss().to(device)\n","\n","        logits_list, labels_list = [], []\n","\n","        print(\"Collecting logits and labels...\")\n","        with torch.no_grad():\n","            for batch in tqdm(valid_loader, desc=\"Processing validation set\", unit=\"batch\"):\n","                inputs = batch['input_ids'].to(device)\n","                labels = batch['label'].to(device)\n","                logits = self.model(inputs).logits\n","                logits_list.append(logits)\n","                labels_list.append(labels)\n","\n","        logits = torch.cat(logits_list, dim=0)\n","        labels = torch.cat(labels_list, dim=0)\n","\n","        before_nll = nll_criterion(logits, labels).item()\n","        before_ece = calculate_ece(logits, labels)\n","        print(f\"Before temperature - NLL: {before_nll:.3f}, ECE: {before_ece:.3f}\")\n","\n","        if output_dir:\n","            make_reliability_diagram(logits, labels, title=f\"Before Temperature Scaling\\nECE: {before_ece:.3f}\",\n","                                     save_path=os.path.join(output_dir, \"before_scaling.png\"))\n","        else:\n","            make_reliability_diagram(logits, labels, title=f\"Before Temperature Scaling\\nECE: {before_ece:.3f}\")\n","\n","        optimizer = optim.LBFGS([self.temperature], lr=0.01, max_iter=50)\n","\n","        def closure():\n","            optimizer.zero_grad()\n","            nll_loss = nll_criterion(self.temperature_scale(logits), labels)\n","            asym_loss = asymmetric_confidence_penalty(self.temperature_scale(logits), labels)\n","            loss = nll_loss + asym_lambda * asym_loss\n","            loss.backward()\n","            return loss\n","\n","        print(f\"Optimizing temperature with asymmetric penalty (lambda={asym_lambda})...\")\n","        optimizer.step(closure)\n","\n","        after_logits = self.temperature_scale(logits)\n","        after_nll = nll_criterion(after_logits, labels).item()\n","        after_ece = calculate_ece(after_logits, labels)\n","\n","        print(f\"Optimal temperature: {self.temperature.item():.3f}\")\n","        print(f\"After temperature - NLL: {after_nll:.3f}, ECE: {after_ece:.3f}\")\n","\n","        if output_dir:\n","            make_reliability_diagram(after_logits, labels, title=f\"After Temperature Scaling\\nECE: {after_ece:.3f}\",\n","                                     save_path=os.path.join(output_dir, \"after_scaling.png\"))\n","            with open(os.path.join(output_dir, \"metrics.txt\"), \"w\") as f:\n","                f.write(f\"Lambda: {asym_lambda}\\n\")\n","                f.write(f\"Before Temp - NLL: {before_nll:.3f}, ECE: {before_ece:.3f}\\n\")\n","                f.write(f\"After Temp - NLL: {after_nll:.3f}, ECE: {after_ece:.3f}\\n\")\n","\n","        torch.save(self.temperature.item(), save_path)\n","        print(f\"Saved optimal temperature to: {save_path}\")\n","\n","        return self\n","\n","def asymmetric_confidence_penalty(logits, labels, threshold=0.7, weight=2.0):\n","    softmaxes = F.softmax(logits, dim=1)\n","    confidences, predictions = torch.max(softmaxes, 1)\n","    is_correct = predictions.eq(labels)\n","    overconfident = confidences \u003e threshold\n","    penalty = torch.where(\n","        is_correct,\n","        torch.zeros_like(confidences),\n","        (confidences - threshold) * overconfident.float() * weight\n","    )\n","    return penalty.mean()\n","\n","def calculate_ece(logits, labels, n_bins=15):\n","    softmaxes = F.softmax(logits, dim=1)\n","    confidences, predictions = torch.max(softmaxes, 1)\n","    accuracies = predictions.eq(labels)\n","\n","    bins = torch.linspace(0, 1, n_bins + 1)\n","    bin_lowers = bins[:-1]\n","    bin_uppers = bins[1:]\n","\n","    ece = 0.0\n","    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n","        in_bin = confidences.ge(bin_lower) * confidences.lt(bin_upper)\n","        prop_in_bin = in_bin.float().mean()\n","        if prop_in_bin.item() \u003e 0:\n","            accuracy_in_bin = accuracies[in_bin].float().mean()\n","            avg_confidence_in_bin = confidences[in_bin].mean()\n","            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n","\n","    return ece.item()\n","\n","def make_reliability_diagram(logits, labels, n_bins=15, title=\"Reliability Diagram\", save_path=None):\n","    softmaxes = F.softmax(logits, dim=1)\n","    confidences, predictions = softmaxes.max(1)\n","    accuracies = predictions.eq(labels)\n","\n","    bins = torch.linspace(0, 1, n_bins + 1)\n","    width = 1.0 / n_bins\n","    bin_centers = np.linspace(0, 1.0 - width, n_bins) + width / 2\n","    bin_indices = [confidences.ge(bin_lower) * confidences.lt(bin_upper) for bin_lower, bin_upper in zip(bins[:-1], bins[1:])]\n","\n","    bin_corrects = np.array([torch.mean(accuracies[bin_idx].float()).item() if bin_idx.any() else 0 for bin_idx in bin_indices])\n","    bin_scores = np.array([torch.mean(confidences[bin_idx].float()).item() if bin_idx.any() else 0 for bin_idx in bin_indices])\n","\n","    plt.figure(figsize=(8, 8))\n","    gap = (bin_scores - bin_corrects)\n","    plt.bar(bin_centers, bin_corrects, width=width, alpha=0.5, ec='black', label='Outputs')\n","    plt.bar(bin_centers, gap, bottom=bin_corrects, color='red', alpha=0.5, width=width, hatch='//', edgecolor='r', label='Gap')\n","    plt.plot([0, 1], [0, 1], '--', color='gray')\n","    plt.legend(loc='best', fontsize='small')\n","\n","    ece = calculate_ece(logits, labels, n_bins)\n","    bbox_props = dict(boxstyle=\"round\", fc=\"lightgrey\", ec=\"brown\", lw=2)\n","    plt.text(0.2, 0.85, f\"ECE: {ece:.2f}\", ha=\"center\", va=\"center\", size=20, weight='bold', bbox=bbox_props)\n","\n","    plt.title(title, size=20)\n","    plt.ylabel(\"Accuracy (P[y])\", size=18)\n","    plt.xlabel(\"Confidence\", size=18)\n","    plt.xlim(0, 1)\n","    plt.ylim(0, 1)\n","\n","    if save_path:\n","        plt.savefig(save_path, dpi=600, bbox_inches=\"tight\")\n","    else:\n","        plt.show()\n","    plt.close()\n","\n","if __name__ == \"__main__\":\n","    model_path = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/models/cyc_30\"\n","    validation_csv = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/data/validation_files/final_selected_val_30.csv\"\n","    pickle_path = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/models/cyc_id_maps/cyc_label_id_map_30.pickle\"\n","    tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8m_UR50D\")\n","    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","    with open(pickle_path, 'rb') as f:\n","        label_mapper = pickle.load(f)\n","    label_mapper = {v: k for k, v in label_mapper.items()}\n","\n","    model = EsmForSequenceClassification.from_pretrained(model_path, num_labels=len(label_mapper))\n","    model_with_temp = ModelWithTemperature(model)\n","\n","    val_dataset = TokenizedDataset(validation_csv, tokenizer, label_mapper)\n","    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n","\n","\n","    base_temp_dir = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_30\"\n","    lambda_list = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n","\n","    for asym_lambda in lambda_list:\n","      output_dir = os.path.join(base_temp_dir, f\"lambda_{asym_lambda}\")\n","      os.makedirs(output_dir, exist_ok=True)\n","      temp_save_path = os.path.join(output_dir, \"optimal_temperature.pt\")\n","\n","      print(f\"Saving results to: {output_dir}\")\n","\n","      model_with_temp.set_temperature(\n","          val_loader,\n","          save_path=temp_save_path,\n","          device=device,\n","          asym_lambda=asym_lambda,\n","          output_dir=output_dir\n","      )\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPnjcjKF5wdbHhJpcTsLMo8","gpuType":"A100","machine_shape":"hm","name":"","provenance":[{"file_id":"1Ka7SLWWjexB9Q4liKQggfUELJXDlKDoK","timestamp":1756854044401},{"file_id":"12L-I6l1D0YcXkwwj4vxAIDVJ1dSqIkkA","timestamp":1756853997295},{"file_id":"1Aq4OjokNgpYCfkgWsNZ_PobKVLXO54sr","timestamp":1756853935921},{"file_id":"1ZHgaOQ90ID_dtgeK1pYVXQt7EUX6qwPR","timestamp":1756853888893},{"file_id":"1DZDJqKvF5R5sl61_rwDmIGh3ELYUunDv","timestamp":1756853688889},{"file_id":"1a1bGN03_Z2eETVz6yz8Azcr9V0PP2Ann","timestamp":1756853428745},{"file_id":"1J_XfwOrwSHRT5uWuQkoLq76e9NQiznce","timestamp":1756852912238},{"file_id":"1YaVjgEn5hQl8fpJgpUMadby1EqkVdbx4","timestamp":1747763126926},{"file_id":"1BgLPAigcgs4f5Xqd1zM1St7wgEjMjzU7","timestamp":1747685035246},{"file_id":"103_0XRq1YLPKwVLpX49vCYq8m4eTWdVz","timestamp":1743651842921}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"06e73cf3de4c4a719a3f124924970c7a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07efc7f88b05492890d28418b1f079c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0856795a4e27495a9c58392380d9912e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1812c600bb9d463b8b408118facec24e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f514f546b574bf9a3ce52eb50ba31ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e609b8121e94046abdb44aa4ee0b1d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"339c4292d82e42b88b64ea2701ddd22c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e1fe890651743a88d78b33d667da1e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53baee9e632e4b9d819055d2aa4b1f5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_339c4292d82e42b88b64ea2701ddd22c","max":93,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd7f3b8d877043f5ba7816884d423148","value":93}},"5ecee5d09a9e4caa9837b5bd7e0ed461":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae93587adc744e3a84380f16a7c8038f","placeholder":"​","style":"IPY_MODEL_8622f0b26a9849c58b8c0a3b6f7b3fbd","value":" 95.0/95.0 [00:00\u0026lt;00:00, 10.4kB/s]"}},"61114a2f742747f8aff82ec900cfc8d1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67731bb17ca04f3b95e036d5cf610d0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68efd0464dfe4e16a5e9b078c4dd3be7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07efc7f88b05492890d28418b1f079c2","max":95,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a584489854041a1ba29d04b8f850892","value":95}},"6a584489854041a1ba29d04b8f850892":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"70f335154b3c48c99b81b4cd1c752a73":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72cafd905085441a90a8e951c3890556":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_740ae257283a45c785260f4243e53439","placeholder":"​","style":"IPY_MODEL_a8a0f449cc6445069fe3f1df6d6704d8","value":"vocab.txt: 100%"}},"740ae257283a45c785260f4243e53439":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8622f0b26a9849c58b8c0a3b6f7b3fbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a60b153c8184decb2d9943084b73599":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"922ab79374664a72bd099282b4ef943c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1812c600bb9d463b8b408118facec24e","placeholder":"​","style":"IPY_MODEL_f2dcf16de0374c4d8d54a1be5882b061","value":" 125/125 [00:00\u0026lt;00:00, 15.5kB/s]"}},"9597c4d70ebd41f78252e06fa66760a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70f335154b3c48c99b81b4cd1c752a73","placeholder":"​","style":"IPY_MODEL_67731bb17ca04f3b95e036d5cf610d0a","value":"special_tokens_map.json: 100%"}},"a8a0f449cc6445069fe3f1df6d6704d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae93587adc744e3a84380f16a7c8038f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"affe57aa72bd4fc1a42d04b9b18ec595":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0856795a4e27495a9c58392380d9912e","placeholder":"​","style":"IPY_MODEL_3e1fe890651743a88d78b33d667da1e0","value":" 93.0/93.0 [00:00\u0026lt;00:00, 11.9kB/s]"}},"b1bde85c3f7747daa9f06f836cbcee1f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4aff5fb5649408fbf611a122f7d9b5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f99a2e21de4b4797928eec73a7c5c063","IPY_MODEL_68efd0464dfe4e16a5e9b078c4dd3be7","IPY_MODEL_5ecee5d09a9e4caa9837b5bd7e0ed461"],"layout":"IPY_MODEL_b1bde85c3f7747daa9f06f836cbcee1f"}},"bd7f3b8d877043f5ba7816884d423148":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"caab387b5c2e4839b085204148fdcdae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9597c4d70ebd41f78252e06fa66760a7","IPY_MODEL_ec6200cb6e174bf597a61bf07340ac0f","IPY_MODEL_922ab79374664a72bd099282b4ef943c"],"layout":"IPY_MODEL_2e609b8121e94046abdb44aa4ee0b1d0"}},"ec6200cb6e174bf597a61bf07340ac0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbf3929e6f3241e1bd1662ddee71d88d","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a60b153c8184decb2d9943084b73599","value":125}},"f2dcf16de0374c4d8d54a1be5882b061":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f861afbc16894dc6a2dc0eedd69fbf2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72cafd905085441a90a8e951c3890556","IPY_MODEL_53baee9e632e4b9d819055d2aa4b1f5d","IPY_MODEL_affe57aa72bd4fc1a42d04b9b18ec595"],"layout":"IPY_MODEL_06e73cf3de4c4a719a3f124924970c7a"}},"f99a2e21de4b4797928eec73a7c5c063":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61114a2f742747f8aff82ec900cfc8d1","placeholder":"​","style":"IPY_MODEL_1f514f546b574bf9a3ce52eb50ba31ba","value":"tokenizer_config.json: 100%"}},"fbf3929e6f3241e1bd1662ddee71d88d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}