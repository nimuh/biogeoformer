{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21397,"status":"ok","timestamp":1756853532937,"user":{"displayName":"Jacob Wynne","userId":"04420788155919199366"},"user_tz":420},"id":"gGAU83p5R-7S","outputId":"95c3406c-7375-4f01-cad2-b87ab6fe0ea0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17860,"status":"ok","timestamp":1756853565502,"user":{"displayName":"Jacob Wynne","userId":"04420788155919199366"},"user_tz":420},"id":"PYcI4CmISmLa","outputId":"4bb2126d-8ea4-40ac-e935-f5ea74b8287d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sympy==1.12\n","  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.12/dist-packages (from sympy==1.12) (1.3.0)\n","Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m215.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m123.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sympy\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.3\n","    Uninstalling sympy-1.13.3:\n","      Successfully uninstalled sympy-1.13.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.8.0+cu126 requires sympy>=1.13.3, but you have sympy 1.12 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed sympy-1.12\n"]}],"source":["pip install sympy==1.12"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":500,"referenced_widgets":["b6a4f77526434effa61578a70649dee4","cc0ef8d3389348799e290699f7db5cef","0aa175b11dbe4804a1ce355f9e174c2f","0052e8adfd6041ba8f0c6f1bf6a0affd","50dc35103d904c498783f54140d43342","12778f9cfe3a40a7a24d9f86f5848513","f6abfc0e10194828a3efce9d207897ee","6eece0074e7247bd99403be7a5102567","f3570493ff7a45c39ffe503df5005058","10cd9ed2d16f440a80ae9c04fb78933a","c1e88ad5ec484771a4c0f2a460f42b8f","bf54962d12fb4f7db95c96e2a84357c9","dd319597c9df48699a296c8f0a8641d6","1fe4efc5bdc44399b5159e01ad928dfb","529b5da59cd744dcac803c8d6b5e9bd9","786b4423d9984a7ebd84243eebcc354a","dce575b35c8a41cd910be8060e2f5a92","291a336cd7bf4211a051271db362c68f","230b1b0773f141619619aec19376c26b","0c77ff37f02049aea2a6901363515992","a92fd64e953840bab7e79de95862727d","40e5bdf5ee434bb5b7eed17f4c281159"]},"id":"elcqeS08ur99","outputId":"7acd0ff0-efb9-4b26-dbaa-0827e36aac0f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/93.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6a4f77526434effa61578a70649dee4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf54962d12fb4f7db95c96e2a84357c9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_80/lambda_0\n","Collecting logits and labels...\n"]},{"output_type":"stream","name":"stderr","text":["Processing validation set:   0%|          | 0/18760 [00:00<?, ?batch/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n","Processing validation set: 100%|██████████| 18760/18760 [25:44<00:00, 12.15batch/s]\n"]},{"output_type":"stream","name":"stdout","text":["Before temperature - NLL: 5.462, ECE: 0.464\n","Optimizing temperature with asymmetric penalty (lambda=0)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/optim/lbfgs.py:457: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n","Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n","  loss = float(closure())\n"]},{"output_type":"stream","name":"stdout","text":["Optimal temperature: 1.771\n","After temperature - NLL: 3.881, ECE: 0.225\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_80/lambda_0/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_80/lambda_10\n","Collecting logits and labels...\n"]},{"output_type":"stream","name":"stderr","text":["Processing validation set: 100%|██████████| 18760/18760 [25:44<00:00, 12.14batch/s]\n"]},{"output_type":"stream","name":"stdout","text":["Before temperature - NLL: 5.462, ECE: 0.464\n","Optimizing temperature with asymmetric penalty (lambda=10)...\n","Optimal temperature: 1.969\n","After temperature - NLL: 3.735, ECE: 0.186\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_80/lambda_10/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_80/lambda_20\n","Collecting logits and labels...\n"]},{"output_type":"stream","name":"stderr","text":["Processing validation set:  63%|██████▎   | 11908/18760 [16:20<09:23, 12.15batch/s]"]}],"source":["import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, EsmForSequenceClassification\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","\n","class TokenizedDataset(Dataset):\n","    def __init__(self, csv_file, tokenizer, label_mapper, max_length=1024):\n","        self.data = pd.read_csv(csv_file)\n","        self.tokenizer = tokenizer\n","        self.label_mapper = label_mapper\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sequence = self.data.iloc[idx]['sequence']\n","        label = self.label_mapper[self.data.iloc[idx]['cycle']]\n","        inputs = self.tokenizer(sequence, return_tensors=\"pt\", padding='max_length',\n","                                truncation=True, max_length=self.max_length)\n","        return {\n","            'input_ids': inputs['input_ids'].squeeze(0),\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","class ModelWithTemperature(nn.Module):\n","    def __init__(self, model):\n","        super(ModelWithTemperature, self).__init__()\n","        self.model = model\n","        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n","\n","    def forward(self, input_ids):\n","        logits = self.model(input_ids).logits\n","        return self.temperature_scale(logits)\n","\n","    def temperature_scale(self, logits):\n","        return logits / self.temperature\n","\n","    def set_temperature(self, valid_loader, save_path, device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\", asym_lambda=50, output_dir=None):\n","        self.to(device)\n","        self.model.eval()\n","        nll_criterion = nn.CrossEntropyLoss().to(device)\n","\n","        logits_list, labels_list = [], []\n","\n","        print(\"Collecting logits and labels...\")\n","        with torch.no_grad():\n","            for batch in tqdm(valid_loader, desc=\"Processing validation set\", unit=\"batch\"):\n","                inputs = batch['input_ids'].to(device)\n","                labels = batch['label'].to(device)\n","                logits = self.model(inputs).logits\n","                logits_list.append(logits)\n","                labels_list.append(labels)\n","\n","        logits = torch.cat(logits_list, dim=0)\n","        labels = torch.cat(labels_list, dim=0)\n","\n","        before_nll = nll_criterion(logits, labels).item()\n","        before_ece = calculate_ece(logits, labels)\n","        print(f\"Before temperature - NLL: {before_nll:.3f}, ECE: {before_ece:.3f}\")\n","\n","        if output_dir:\n","            make_reliability_diagram(logits, labels, title=f\"Before Temperature Scaling\\nECE: {before_ece:.3f}\",\n","                                     save_path=os.path.join(output_dir, \"before_scaling.png\"))\n","        else:\n","            make_reliability_diagram(logits, labels, title=f\"Before Temperature Scaling\\nECE: {before_ece:.3f}\")\n","\n","        optimizer = optim.LBFGS([self.temperature], lr=0.01, max_iter=50)\n","\n","        def closure():\n","            optimizer.zero_grad()\n","            nll_loss = nll_criterion(self.temperature_scale(logits), labels)\n","            asym_loss = asymmetric_confidence_penalty(self.temperature_scale(logits), labels)\n","            loss = nll_loss + asym_lambda * asym_loss\n","            loss.backward()\n","            return loss\n","\n","        print(f\"Optimizing temperature with asymmetric penalty (lambda={asym_lambda})...\")\n","        optimizer.step(closure)\n","\n","        after_logits = self.temperature_scale(logits)\n","        after_nll = nll_criterion(after_logits, labels).item()\n","        after_ece = calculate_ece(after_logits, labels)\n","\n","        print(f\"Optimal temperature: {self.temperature.item():.3f}\")\n","        print(f\"After temperature - NLL: {after_nll:.3f}, ECE: {after_ece:.3f}\")\n","\n","        if output_dir:\n","            make_reliability_diagram(after_logits, labels, title=f\"After Temperature Scaling\\nECE: {after_ece:.3f}\",\n","                                     save_path=os.path.join(output_dir, \"after_scaling.png\"))\n","            with open(os.path.join(output_dir, \"metrics.txt\"), \"w\") as f:\n","                f.write(f\"Lambda: {asym_lambda}\\n\")\n","                f.write(f\"Before Temp - NLL: {before_nll:.3f}, ECE: {before_ece:.3f}\\n\")\n","                f.write(f\"After Temp - NLL: {after_nll:.3f}, ECE: {after_ece:.3f}\\n\")\n","\n","        torch.save(self.temperature.item(), save_path)\n","        print(f\"Saved optimal temperature to: {save_path}\")\n","\n","        return self\n","\n","def asymmetric_confidence_penalty(logits, labels, threshold=0.7, weight=2.0):\n","    softmaxes = F.softmax(logits, dim=1)\n","    confidences, predictions = torch.max(softmaxes, 1)\n","    is_correct = predictions.eq(labels)\n","    overconfident = confidences > threshold\n","    penalty = torch.where(\n","        is_correct,\n","        torch.zeros_like(confidences),\n","        (confidences - threshold) * overconfident.float() * weight\n","    )\n","    return penalty.mean()\n","\n","def calculate_ece(logits, labels, n_bins=15):\n","    softmaxes = F.softmax(logits, dim=1)\n","    confidences, predictions = torch.max(softmaxes, 1)\n","    accuracies = predictions.eq(labels)\n","\n","    bins = torch.linspace(0, 1, n_bins + 1)\n","    bin_lowers = bins[:-1]\n","    bin_uppers = bins[1:]\n","\n","    ece = 0.0\n","    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n","        in_bin = confidences.ge(bin_lower) * confidences.lt(bin_upper)\n","        prop_in_bin = in_bin.float().mean()\n","        if prop_in_bin.item() > 0:\n","            accuracy_in_bin = accuracies[in_bin].float().mean()\n","            avg_confidence_in_bin = confidences[in_bin].mean()\n","            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n","\n","    return ece.item()\n","\n","def make_reliability_diagram(logits, labels, n_bins=15, title=\"Reliability Diagram\", save_path=None):\n","    softmaxes = F.softmax(logits, dim=1)\n","    confidences, predictions = softmaxes.max(1)\n","    accuracies = predictions.eq(labels)\n","\n","    bins = torch.linspace(0, 1, n_bins + 1)\n","    width = 1.0 / n_bins\n","    bin_centers = np.linspace(0, 1.0 - width, n_bins) + width / 2\n","    bin_indices = [confidences.ge(bin_lower) * confidences.lt(bin_upper) for bin_lower, bin_upper in zip(bins[:-1], bins[1:])]\n","\n","    bin_corrects = np.array([torch.mean(accuracies[bin_idx].float()).item() if bin_idx.any() else 0 for bin_idx in bin_indices])\n","    bin_scores = np.array([torch.mean(confidences[bin_idx].float()).item() if bin_idx.any() else 0 for bin_idx in bin_indices])\n","\n","    plt.figure(figsize=(8, 8))\n","    gap = (bin_scores - bin_corrects)\n","    plt.bar(bin_centers, bin_corrects, width=width, alpha=0.5, ec='black', label='Outputs')\n","    plt.bar(bin_centers, gap, bottom=bin_corrects, color='red', alpha=0.5, width=width, hatch='//', edgecolor='r', label='Gap')\n","    plt.plot([0, 1], [0, 1], '--', color='gray')\n","    plt.legend(loc='best', fontsize='small')\n","\n","    ece = calculate_ece(logits, labels, n_bins)\n","    bbox_props = dict(boxstyle=\"round\", fc=\"lightgrey\", ec=\"brown\", lw=2)\n","    plt.text(0.2, 0.85, f\"ECE: {ece:.2f}\", ha=\"center\", va=\"center\", size=20, weight='bold', bbox=bbox_props)\n","\n","    plt.title(title, size=20)\n","    plt.ylabel(\"Accuracy (P[y])\", size=18)\n","    plt.xlabel(\"Confidence\", size=18)\n","    plt.xlim(0, 1)\n","    plt.ylim(0, 1)\n","\n","    if save_path:\n","        plt.savefig(save_path, dpi=600, bbox_inches=\"tight\")\n","    else:\n","        plt.show()\n","    plt.close()\n","\n","if __name__ == \"__main__\":\n","    model_path = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/models/cyc_80\"\n","    validation_csv = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/data/validation_files/final_selected_val_80.csv\"\n","    pickle_path = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/models/cyc_id_maps/cyc_label_id_map_80.pickle\"\n","    tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8m_UR50D\")\n","    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","    with open(pickle_path, 'rb') as f:\n","        label_mapper = pickle.load(f)\n","    label_mapper = {v: k for k, v in label_mapper.items()}\n","\n","    model = EsmForSequenceClassification.from_pretrained(model_path, num_labels=len(label_mapper))\n","    model_with_temp = ModelWithTemperature(model)\n","\n","    val_dataset = TokenizedDataset(validation_csv, tokenizer, label_mapper)\n","    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n","\n","\n","    base_temp_dir = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_80\"\n","    lambda_list = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n","\n","    for asym_lambda in lambda_list:\n","      output_dir = os.path.join(base_temp_dir, f\"lambda_{asym_lambda}\")\n","      os.makedirs(output_dir, exist_ok=True)\n","      temp_save_path = os.path.join(output_dir, \"optimal_temperature.pt\")\n","\n","      print(f\"Saving results to: {output_dir}\")\n","\n","      model_with_temp.set_temperature(\n","          val_loader,\n","          save_path=temp_save_path,\n","          device=device,\n","          asym_lambda=asym_lambda,\n","          output_dir=output_dir\n","      )\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1a1bGN03_Z2eETVz6yz8Azcr9V0PP2Ann","timestamp":1756853428745},{"file_id":"1J_XfwOrwSHRT5uWuQkoLq76e9NQiznce","timestamp":1756852912238},{"file_id":"1YaVjgEn5hQl8fpJgpUMadby1EqkVdbx4","timestamp":1747763126926},{"file_id":"1BgLPAigcgs4f5Xqd1zM1St7wgEjMjzU7","timestamp":1747685035246},{"file_id":"103_0XRq1YLPKwVLpX49vCYq8m4eTWdVz","timestamp":1743651842921}],"authorship_tag":"ABX9TyMo9ZkK90lI8SXEAIYKmY82"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b6a4f77526434effa61578a70649dee4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc0ef8d3389348799e290699f7db5cef","IPY_MODEL_0aa175b11dbe4804a1ce355f9e174c2f","IPY_MODEL_0052e8adfd6041ba8f0c6f1bf6a0affd"],"layout":"IPY_MODEL_50dc35103d904c498783f54140d43342"}},"cc0ef8d3389348799e290699f7db5cef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12778f9cfe3a40a7a24d9f86f5848513","placeholder":"​","style":"IPY_MODEL_f6abfc0e10194828a3efce9d207897ee","value":"vocab.txt: 100%"}},"0aa175b11dbe4804a1ce355f9e174c2f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6eece0074e7247bd99403be7a5102567","max":93,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3570493ff7a45c39ffe503df5005058","value":93}},"0052e8adfd6041ba8f0c6f1bf6a0affd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10cd9ed2d16f440a80ae9c04fb78933a","placeholder":"​","style":"IPY_MODEL_c1e88ad5ec484771a4c0f2a460f42b8f","value":" 93.0/93.0 [00:00&lt;00:00, 11.2kB/s]"}},"50dc35103d904c498783f54140d43342":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12778f9cfe3a40a7a24d9f86f5848513":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6abfc0e10194828a3efce9d207897ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6eece0074e7247bd99403be7a5102567":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3570493ff7a45c39ffe503df5005058":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"10cd9ed2d16f440a80ae9c04fb78933a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1e88ad5ec484771a4c0f2a460f42b8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf54962d12fb4f7db95c96e2a84357c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd319597c9df48699a296c8f0a8641d6","IPY_MODEL_1fe4efc5bdc44399b5159e01ad928dfb","IPY_MODEL_529b5da59cd744dcac803c8d6b5e9bd9"],"layout":"IPY_MODEL_786b4423d9984a7ebd84243eebcc354a"}},"dd319597c9df48699a296c8f0a8641d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dce575b35c8a41cd910be8060e2f5a92","placeholder":"​","style":"IPY_MODEL_291a336cd7bf4211a051271db362c68f","value":"special_tokens_map.json: 100%"}},"1fe4efc5bdc44399b5159e01ad928dfb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_230b1b0773f141619619aec19376c26b","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c77ff37f02049aea2a6901363515992","value":125}},"529b5da59cd744dcac803c8d6b5e9bd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a92fd64e953840bab7e79de95862727d","placeholder":"​","style":"IPY_MODEL_40e5bdf5ee434bb5b7eed17f4c281159","value":" 125/125 [00:00&lt;00:00, 13.4kB/s]"}},"786b4423d9984a7ebd84243eebcc354a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dce575b35c8a41cd910be8060e2f5a92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"291a336cd7bf4211a051271db362c68f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"230b1b0773f141619619aec19376c26b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c77ff37f02049aea2a6901363515992":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a92fd64e953840bab7e79de95862727d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40e5bdf5ee434bb5b7eed17f4c281159":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}