{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22718,"status":"ok","timestamp":1756875152457,"user":{"displayName":"Jacob Wynne","userId":"04420788155919199366"},"user_tz":420},"id":"gGAU83p5R-7S","outputId":"6ae792ba-3c2e-4559-8b9d-41220d96ba1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18115,"status":"ok","timestamp":1756875170576,"user":{"displayName":"Jacob Wynne","userId":"04420788155919199366"},"user_tz":420},"id":"PYcI4CmISmLa","outputId":"e3b75270-e8c0-4a07-c1b9-2ee3e5d29b85"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sympy==1.12\n","  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.12/dist-packages (from sympy==1.12) (1.3.0)\n","Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m216.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sympy\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.3\n","    Uninstalling sympy-1.13.3:\n","      Successfully uninstalled sympy-1.13.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.8.0+cu126 requires sympy\u003e=1.13.3, but you have sympy 1.12 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed sympy-1.12\n"]}],"source":["pip install sympy==1.12"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":307},"id":"elcqeS08ur99"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f3f2cce809948588dc023a361394782","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/95.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cd1a9546c1e49878ddbb8ba1caf1f3d","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/93.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f8fc05d4cb940ffa7616250e416d0f6","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_0\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set:   0%|          | 0/15139 [00:00\u003c?, ?batch/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n","Processing validation set: 100%|██████████| 15139/15139 [20:45\u003c00:00, 12.15batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.979, ECE: 0.441\n","Optimizing temperature with asymmetric penalty (lambda=0)...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/torch/optim/lbfgs.py:457: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n","Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n","  loss = float(closure())\n"]},{"name":"stdout","output_type":"stream","text":["Optimal temperature: 1.758\n","After temperature - NLL: 3.612, ECE: 0.209\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_0/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_10\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 15139/15139 [20:45\u003c00:00, 12.15batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.979, ECE: 0.441\n","Optimizing temperature with asymmetric penalty (lambda=10)...\n","Optimal temperature: 1.972\n","After temperature - NLL: 3.480, ECE: 0.170\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_10/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_20\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 15139/15139 [20:45\u003c00:00, 12.16batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.979, ECE: 0.441\n","Optimizing temperature with asymmetric penalty (lambda=20)...\n","Optimal temperature: 2.192\n","After temperature - NLL: 3.390, ECE: 0.141\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_20/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_30\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 15139/15139 [20:45\u003c00:00, 12.15batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.979, ECE: 0.441\n","Optimizing temperature with asymmetric penalty (lambda=30)...\n","Optimal temperature: 2.363\n","After temperature - NLL: 3.343, ECE: 0.126\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_30/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_40\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 15139/15139 [20:45\u003c00:00, 12.16batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.979, ECE: 0.441\n","Optimizing temperature with asymmetric penalty (lambda=40)...\n","Optimal temperature: 2.576\n","After temperature - NLL: 3.303, ECE: 0.113\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_40/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_50\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 15139/15139 [20:45\u003c00:00, 12.16batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.979, ECE: 0.441\n","Optimizing temperature with asymmetric penalty (lambda=50)...\n","Optimal temperature: 2.745\n","After temperature - NLL: 3.283, ECE: 0.108\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_50/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_60\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 15139/15139 [20:46\u003c00:00, 12.15batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.979, ECE: 0.441\n","Optimizing temperature with asymmetric penalty (lambda=60)...\n","Optimal temperature: 2.905\n","After temperature - NLL: 3.269, ECE: 0.104\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_60/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_70\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 15139/15139 [20:45\u003c00:00, 12.15batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.979, ECE: 0.441\n","Optimizing temperature with asymmetric penalty (lambda=70)...\n","Optimal temperature: 3.070\n","After temperature - NLL: 3.260, ECE: 0.103\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_70/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_80\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 15139/15139 [20:45\u003c00:00, 12.15batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.979, ECE: 0.441\n","Optimizing temperature with asymmetric penalty (lambda=80)...\n","Optimal temperature: 3.200\n","After temperature - NLL: 3.256, ECE: 0.100\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_80/optimal_temperature.pt\n","Saving results to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_90\n","Collecting logits and labels...\n"]},{"name":"stderr","output_type":"stream","text":["Processing validation set: 100%|██████████| 15139/15139 [20:46\u003c00:00, 12.15batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 4.979, ECE: 0.441\n","Optimizing temperature with asymmetric penalty (lambda=90)...\n","Optimal temperature: 3.297\n","After temperature - NLL: 3.254, ECE: 0.098\n","Saved optimal temperature to: /content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50/lambda_90/optimal_temperature.pt\n"]}],"source":["import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, EsmForSequenceClassification\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","\n","class TokenizedDataset(Dataset):\n","    def __init__(self, csv_file, tokenizer, label_mapper, max_length=1024):\n","        self.data = pd.read_csv(csv_file)\n","        self.tokenizer = tokenizer\n","        self.label_mapper = label_mapper\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sequence = self.data.iloc[idx]['sequence']\n","        label = self.label_mapper[self.data.iloc[idx]['cycle']]\n","        inputs = self.tokenizer(sequence, return_tensors=\"pt\", padding='max_length',\n","                                truncation=True, max_length=self.max_length)\n","        return {\n","            'input_ids': inputs['input_ids'].squeeze(0),\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","class ModelWithTemperature(nn.Module):\n","    def __init__(self, model):\n","        super(ModelWithTemperature, self).__init__()\n","        self.model = model\n","        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n","\n","    def forward(self, input_ids):\n","        logits = self.model(input_ids).logits\n","        return self.temperature_scale(logits)\n","\n","    def temperature_scale(self, logits):\n","        return logits / self.temperature\n","\n","    def set_temperature(self, valid_loader, save_path, device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\", asym_lambda=50, output_dir=None):\n","        self.to(device)\n","        self.model.eval()\n","        nll_criterion = nn.CrossEntropyLoss().to(device)\n","\n","        logits_list, labels_list = [], []\n","\n","        print(\"Collecting logits and labels...\")\n","        with torch.no_grad():\n","            for batch in tqdm(valid_loader, desc=\"Processing validation set\", unit=\"batch\"):\n","                inputs = batch['input_ids'].to(device)\n","                labels = batch['label'].to(device)\n","                logits = self.model(inputs).logits\n","                logits_list.append(logits)\n","                labels_list.append(labels)\n","\n","        logits = torch.cat(logits_list, dim=0)\n","        labels = torch.cat(labels_list, dim=0)\n","\n","        before_nll = nll_criterion(logits, labels).item()\n","        before_ece = calculate_ece(logits, labels)\n","        print(f\"Before temperature - NLL: {before_nll:.3f}, ECE: {before_ece:.3f}\")\n","\n","        if output_dir:\n","            make_reliability_diagram(logits, labels, title=f\"Before Temperature Scaling\\nECE: {before_ece:.3f}\",\n","                                     save_path=os.path.join(output_dir, \"before_scaling.png\"))\n","        else:\n","            make_reliability_diagram(logits, labels, title=f\"Before Temperature Scaling\\nECE: {before_ece:.3f}\")\n","\n","        optimizer = optim.LBFGS([self.temperature], lr=0.01, max_iter=50)\n","\n","        def closure():\n","            optimizer.zero_grad()\n","            nll_loss = nll_criterion(self.temperature_scale(logits), labels)\n","            asym_loss = asymmetric_confidence_penalty(self.temperature_scale(logits), labels)\n","            loss = nll_loss + asym_lambda * asym_loss\n","            loss.backward()\n","            return loss\n","\n","        print(f\"Optimizing temperature with asymmetric penalty (lambda={asym_lambda})...\")\n","        optimizer.step(closure)\n","\n","        after_logits = self.temperature_scale(logits)\n","        after_nll = nll_criterion(after_logits, labels).item()\n","        after_ece = calculate_ece(after_logits, labels)\n","\n","        print(f\"Optimal temperature: {self.temperature.item():.3f}\")\n","        print(f\"After temperature - NLL: {after_nll:.3f}, ECE: {after_ece:.3f}\")\n","\n","        if output_dir:\n","            make_reliability_diagram(after_logits, labels, title=f\"After Temperature Scaling\\nECE: {after_ece:.3f}\",\n","                                     save_path=os.path.join(output_dir, \"after_scaling.png\"))\n","            with open(os.path.join(output_dir, \"metrics.txt\"), \"w\") as f:\n","                f.write(f\"Lambda: {asym_lambda}\\n\")\n","                f.write(f\"Before Temp - NLL: {before_nll:.3f}, ECE: {before_ece:.3f}\\n\")\n","                f.write(f\"After Temp - NLL: {after_nll:.3f}, ECE: {after_ece:.3f}\\n\")\n","\n","        torch.save(self.temperature.item(), save_path)\n","        print(f\"Saved optimal temperature to: {save_path}\")\n","\n","        return self\n","\n","def asymmetric_confidence_penalty(logits, labels, threshold=0.7, weight=2.0):\n","    softmaxes = F.softmax(logits, dim=1)\n","    confidences, predictions = torch.max(softmaxes, 1)\n","    is_correct = predictions.eq(labels)\n","    overconfident = confidences \u003e threshold\n","    penalty = torch.where(\n","        is_correct,\n","        torch.zeros_like(confidences),\n","        (confidences - threshold) * overconfident.float() * weight\n","    )\n","    return penalty.mean()\n","\n","def calculate_ece(logits, labels, n_bins=15):\n","    softmaxes = F.softmax(logits, dim=1)\n","    confidences, predictions = torch.max(softmaxes, 1)\n","    accuracies = predictions.eq(labels)\n","\n","    bins = torch.linspace(0, 1, n_bins + 1)\n","    bin_lowers = bins[:-1]\n","    bin_uppers = bins[1:]\n","\n","    ece = 0.0\n","    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n","        in_bin = confidences.ge(bin_lower) * confidences.lt(bin_upper)\n","        prop_in_bin = in_bin.float().mean()\n","        if prop_in_bin.item() \u003e 0:\n","            accuracy_in_bin = accuracies[in_bin].float().mean()\n","            avg_confidence_in_bin = confidences[in_bin].mean()\n","            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n","\n","    return ece.item()\n","\n","def make_reliability_diagram(logits, labels, n_bins=15, title=\"Reliability Diagram\", save_path=None):\n","    softmaxes = F.softmax(logits, dim=1)\n","    confidences, predictions = softmaxes.max(1)\n","    accuracies = predictions.eq(labels)\n","\n","    bins = torch.linspace(0, 1, n_bins + 1)\n","    width = 1.0 / n_bins\n","    bin_centers = np.linspace(0, 1.0 - width, n_bins) + width / 2\n","    bin_indices = [confidences.ge(bin_lower) * confidences.lt(bin_upper) for bin_lower, bin_upper in zip(bins[:-1], bins[1:])]\n","\n","    bin_corrects = np.array([torch.mean(accuracies[bin_idx].float()).item() if bin_idx.any() else 0 for bin_idx in bin_indices])\n","    bin_scores = np.array([torch.mean(confidences[bin_idx].float()).item() if bin_idx.any() else 0 for bin_idx in bin_indices])\n","\n","    plt.figure(figsize=(8, 8))\n","    gap = (bin_scores - bin_corrects)\n","    plt.bar(bin_centers, bin_corrects, width=width, alpha=0.5, ec='black', label='Outputs')\n","    plt.bar(bin_centers, gap, bottom=bin_corrects, color='red', alpha=0.5, width=width, hatch='//', edgecolor='r', label='Gap')\n","    plt.plot([0, 1], [0, 1], '--', color='gray')\n","    plt.legend(loc='best', fontsize='small')\n","\n","    ece = calculate_ece(logits, labels, n_bins)\n","    bbox_props = dict(boxstyle=\"round\", fc=\"lightgrey\", ec=\"brown\", lw=2)\n","    plt.text(0.2, 0.85, f\"ECE: {ece:.2f}\", ha=\"center\", va=\"center\", size=20, weight='bold', bbox=bbox_props)\n","\n","    plt.title(title, size=20)\n","    plt.ylabel(\"Accuracy (P[y])\", size=18)\n","    plt.xlabel(\"Confidence\", size=18)\n","    plt.xlim(0, 1)\n","    plt.ylim(0, 1)\n","\n","    if save_path:\n","        plt.savefig(save_path, dpi=600, bbox_inches=\"tight\")\n","    else:\n","        plt.show()\n","    plt.close()\n","\n","if __name__ == \"__main__\":\n","    model_path = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/models/cyc_50\"\n","    validation_csv = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/data/validation_files/final_selected_val_50.csv\"\n","    pickle_path = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/models/cyc_id_maps/cyc_label_id_map_50.pickle\"\n","    tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8m_UR50D\")\n","    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","    with open(pickle_path, 'rb') as f:\n","        label_mapper = pickle.load(f)\n","    label_mapper = {v: k for k, v in label_mapper.items()}\n","\n","    model = EsmForSequenceClassification.from_pretrained(model_path, num_labels=len(label_mapper))\n","    model_with_temp = ModelWithTemperature(model)\n","\n","    val_dataset = TokenizedDataset(validation_csv, tokenizer, label_mapper)\n","    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n","\n","\n","    base_temp_dir = \"/content/drive/MyDrive/cycformer_run/cycformer_sep2/cycformer/temperature_scaling/cyc_50\"\n","    lambda_list = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n","\n","    for asym_lambda in lambda_list:\n","      output_dir = os.path.join(base_temp_dir, f\"lambda_{asym_lambda}\")\n","      os.makedirs(output_dir, exist_ok=True)\n","      temp_save_path = os.path.join(output_dir, \"optimal_temperature.pt\")\n","\n","      print(f\"Saving results to: {output_dir}\")\n","\n","      model_with_temp.set_temperature(\n","          val_loader,\n","          save_path=temp_save_path,\n","          device=device,\n","          asym_lambda=asym_lambda,\n","          output_dir=output_dir\n","      )\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOSj5tiS2rMHWeWZXnEbRte","gpuType":"A100","machine_shape":"hm","name":"","provenance":[{"file_id":"1Aq4OjokNgpYCfkgWsNZ_PobKVLXO54sr","timestamp":1756853935921},{"file_id":"1ZHgaOQ90ID_dtgeK1pYVXQt7EUX6qwPR","timestamp":1756853888893},{"file_id":"1DZDJqKvF5R5sl61_rwDmIGh3ELYUunDv","timestamp":1756853688889},{"file_id":"1a1bGN03_Z2eETVz6yz8Azcr9V0PP2Ann","timestamp":1756853428745},{"file_id":"1J_XfwOrwSHRT5uWuQkoLq76e9NQiznce","timestamp":1756852912238},{"file_id":"1YaVjgEn5hQl8fpJgpUMadby1EqkVdbx4","timestamp":1747763126926},{"file_id":"1BgLPAigcgs4f5Xqd1zM1St7wgEjMjzU7","timestamp":1747685035246},{"file_id":"103_0XRq1YLPKwVLpX49vCYq8m4eTWdVz","timestamp":1743651842921}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"048256e7b78f4c4e9f645779c831e13d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ca1fc5b6e2f43eabb727a762e99ec73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b89da4ca471447789af86535bf3c7bd","max":93,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1d621a02ab243cc87b8ecbe6e5b7bfc","value":93}},"14554b8e78af403298112fcb9443580a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f3f2cce809948588dc023a361394782":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_955d09e01a4945c69c09c71480d21ea7","IPY_MODEL_76ed3179433f4baab6c7512f6f7a46ef","IPY_MODEL_1f6c2946970d4df78e1820ac7bc4edb6"],"layout":"IPY_MODEL_76f9bc929205409bbc9bef53a08be414"}},"1f6c2946970d4df78e1820ac7bc4edb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3296bdb9ca544728367c37edf74100b","placeholder":"​","style":"IPY_MODEL_f4dce85d7a4f444fb92a887d02fc8fd9","value":" 95.0/95.0 [00:00\u0026lt;00:00, 10.5kB/s]"}},"2422d70932294ec8bcafbea1879e811b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"293fb3e4346f48249b309839f0c3031f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2af188a5ad39436bb68095b1f2db137e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e850ad9aca747eda6457cf5053d6e98","placeholder":"​","style":"IPY_MODEL_293fb3e4346f48249b309839f0c3031f","value":"vocab.txt: 100%"}},"2e4a8915d92a4819a346593294db62ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6c2bcb7e4d246148efbb2cac57db88f","placeholder":"​","style":"IPY_MODEL_9a63a380425f4be887f94eaaf7bab2f6","value":"special_tokens_map.json: 100%"}},"32263a23541a4934bee37413ab6b24d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b4b16bb1a8d427784aa901a013a91ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75ab4a2ff9f6458686d6a1ebdd6ec10f","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_728e0425cab14e438b5266543d8edde6","value":125}},"3c1cc17ba778449db65587f94f8aee27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cd1a9546c1e49878ddbb8ba1caf1f3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2af188a5ad39436bb68095b1f2db137e","IPY_MODEL_0ca1fc5b6e2f43eabb727a762e99ec73","IPY_MODEL_62f7ee9bf3fb4007993fea237e77e066"],"layout":"IPY_MODEL_14554b8e78af403298112fcb9443580a"}},"3f8fc05d4cb940ffa7616250e416d0f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e4a8915d92a4819a346593294db62ed","IPY_MODEL_3b4b16bb1a8d427784aa901a013a91ec","IPY_MODEL_6c2dd56808d444788a99fb1bfcec52e5"],"layout":"IPY_MODEL_e0b75ebecdc74d9b910a62c1d39580e7"}},"6275c1c0d3cb47ccb518cb255c05e6fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62f7ee9bf3fb4007993fea237e77e066":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f2636abe6e14132833d2855eb7e0240","placeholder":"​","style":"IPY_MODEL_2422d70932294ec8bcafbea1879e811b","value":" 93.0/93.0 [00:00\u0026lt;00:00, 11.9kB/s]"}},"6b89da4ca471447789af86535bf3c7bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c2dd56808d444788a99fb1bfcec52e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6275c1c0d3cb47ccb518cb255c05e6fa","placeholder":"​","style":"IPY_MODEL_3c1cc17ba778449db65587f94f8aee27","value":" 125/125 [00:00\u0026lt;00:00, 10.8kB/s]"}},"6f2636abe6e14132833d2855eb7e0240":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"728e0425cab14e438b5266543d8edde6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75ab4a2ff9f6458686d6a1ebdd6ec10f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76ed3179433f4baab6c7512f6f7a46ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_048256e7b78f4c4e9f645779c831e13d","max":95,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf39bd05b17b44babad639be6a448ff7","value":95}},"76f9bc929205409bbc9bef53a08be414":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e850ad9aca747eda6457cf5053d6e98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"955d09e01a4945c69c09c71480d21ea7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5ccb15acd7d4260aa14feb529288746","placeholder":"​","style":"IPY_MODEL_32263a23541a4934bee37413ab6b24d2","value":"tokenizer_config.json: 100%"}},"9a63a380425f4be887f94eaaf7bab2f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3296bdb9ca544728367c37edf74100b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf39bd05b17b44babad639be6a448ff7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e0b75ebecdc74d9b910a62c1d39580e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1d621a02ab243cc87b8ecbe6e5b7bfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5ccb15acd7d4260aa14feb529288746":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6c2bcb7e4d246148efbb2cac57db88f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4dce85d7a4f444fb92a887d02fc8fd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}